{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_UNET.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNBsIG9lHekiMkU2ist0jiP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iBXNbvMLPoY3","colab_type":"text"},"source":["---\n","\n","# ***05 - UNET***\n","\n","---\n","\n","**Aprendizagem de Máquina**\n","\n","Gustavo H. G. Matsushita (gustavomatsushita@ufpr.br)\n","\n","Prof. Luiz Eduardo S. Oliveira (luiz.oliveira@ufpr.br)\n","\n","---\n","\n","**Universidade Federal do Paraná**\n","\n","Departamento de Informática\n","\n","http://web.inf.ufpr.br/luizoliveira\n","\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"0Rvv0QRYlFCN","colab_type":"text"},"source":["\n","**ISBI Challenge:** http://brainiac2.mit.edu/isbi_challenge/\n","\n","**Unet using Keras:** https://github.com/zhixuhao/unet/"]},{"cell_type":"markdown","metadata":{"id":"kBGQYdX7ww5Z","colab_type":"text"},"source":["#Importando do Google Drive"]},{"cell_type":"code","metadata":{"id":"NYrRT74AwoIz","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_A1VYGHzRgks","colab_type":"text"},"source":["#Verificando GPU"]},{"cell_type":"code","metadata":{"id":"mksTnlljPcCt","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lppn1n_3Etbj","colab_type":"text"},"source":["#Definindo algumas variáveis"]},{"cell_type":"code","metadata":{"id":"DN9-TpiKgEld","colab_type":"code","colab":{}},"source":["## Google Drive\n","drive_path = '/content/drive/My Drive/Colab Notebooks/Aulas/unet/'\n","\n","## Train and Test path\n","train_path = drive_path + 'membrane/train/'\n","test_path = drive_path + 'membrane/test/'\n","aug_path = drive_path + 'membrane/aug/'\n","results_path = drive_path + 'membrane/predict/'\n","\n","print(\"Train:\",train_path)\n","print(\"Test:\",test_path)\n","print(\"Aug:\",aug_path)\n","print(\"Res:\",results_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1YaROwvgIo8O","colab_type":"text"},"source":["#Módulos e Funções"]},{"cell_type":"code","metadata":{"id":"vQtZr5cFowWP","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np \n","import os\n","import glob\n","import skimage.io as io\n","import skimage.transform as trans\n","from skimage import img_as_ubyte\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras\n","\n","\n","Sky = [128,128,128]\n","Building = [128,0,0]\n","Pole = [192,192,128]\n","Road = [128,64,128]\n","Pavement = [60,40,222]\n","Tree = [128,128,0]\n","SignSymbol = [192,128,128]\n","Fence = [64,64,128]\n","Car = [64,0,128]\n","Pedestrian = [64,64,0]\n","Bicyclist = [0,128,192]\n","Unlabelled = [0,0,0]\n","\n","COLOR_DICT = np.array([Sky, Building, Pole, Road, Pavement, Tree, SignSymbol, Fence, Car, Pedestrian, Bicyclist, Unlabelled])\n","\n","\n","def adjustData(img,mask,flag_multi_class,num_class):\n","  if(flag_multi_class):\n","    img = img / 255\n","    mask = mask[:,:,:,0] if(len(mask.shape) == 4) else mask[:,:,0]\n","    new_mask = np.zeros(mask.shape + (num_class,))\n","    for i in range(num_class):\n","      #for one pixel in the image, find the class in mask and convert it into one-hot vector\n","      #index = np.where(mask == i)\n","      #index_mask = (index[0],index[1],index[2],np.zeros(len(index[0]),dtype = np.int64) + i) if (len(mask.shape) == 4) else (index[0],index[1],np.zeros(len(index[0]),dtype = np.int64) + i)\n","      #new_mask[index_mask] = 1\n","      new_mask[mask == i,i] = 1\n","    new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flag_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n","    mask = new_mask\n","  elif(np.max(img) > 1):\n","    img = img / 255\n","    mask = mask /255\n","    mask[mask > 0.5] = 1\n","    mask[mask <= 0.5] = 0\n","  return (img,mask)\n","\n","\n","\n","def trainGenerator(batch_size,train_path,image_folder,mask_folder,aug_dict,image_color_mode = \"grayscale\",\n","                    mask_color_mode = \"grayscale\",image_save_prefix  = \"image\",mask_save_prefix  = \"mask\",\n","                    flag_multi_class = False,num_class = 2,save_to_dir = None,target_size = (256,256),seed = 1):\n","  image_datagen = ImageDataGenerator(**aug_dict)\n","  mask_datagen = ImageDataGenerator(**aug_dict)\n","  image_generator = image_datagen.flow_from_directory(\n","    train_path,\n","    classes = [image_folder],\n","    class_mode = None,\n","    color_mode = image_color_mode,\n","    target_size = target_size,\n","    batch_size = batch_size,\n","    save_to_dir = save_to_dir,\n","    save_prefix  = image_save_prefix,\n","    seed = seed)\n","  mask_generator = mask_datagen.flow_from_directory(\n","    train_path,\n","    classes = [mask_folder],\n","    class_mode = None,\n","    color_mode = mask_color_mode,\n","    target_size = target_size,\n","    batch_size = batch_size,\n","    save_to_dir = save_to_dir,\n","    save_prefix  = mask_save_prefix,\n","    seed = seed)\n","  train_generator = zip(image_generator, mask_generator)\n","  for (img,mask) in train_generator:\n","    img,mask = adjustData(img,mask,flag_multi_class,num_class)\n","    yield (img,mask)\n","\n","\n","\n","def testGenerator(test_path,num_image = 30,target_size = (256,256),flag_multi_class = False,as_gray = True):\n","  for i in range(num_image):\n","    img = io.imread(os.path.join(test_path,\"%d.png\"%i),as_gray = as_gray)\n","    img = img / 255\n","    img = trans.resize(img,target_size)\n","    img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n","    img = np.reshape(img,(1,)+img.shape)\n","    yield img\n","\n","\n","def labelVisualize(num_class,color_dict,img):\n","  img = img[:,:,0] if len(img.shape) == 3 else img\n","  img_out = np.zeros(img.shape + (3,))\n","  for i in range(num_class):\n","    img_out[img == i,:] = color_dict[i]\n","  return img_out / 255\n","\n","\n","def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n","  for i,item in enumerate(npyfile):\n","    img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n","    io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n","    #io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img_as_ubyte(img))\n","\n","\n","print('Done')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lKZqo-LJIvWe","colab_type":"text"},"source":["#Modelo UNET"]},{"cell_type":"code","metadata":{"id":"PUkTDfKaqAiT","colab_type":"code","colab":{}},"source":["def unet(pretrained_weights = None,input_size = (256,256,1)):\n","\n","  inputs = Input(input_size)\n","  \n","  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","  \n","  ##\n","  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","  ##\n","\n","  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","  \n","  ##\n","  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","  ##\n","\n","  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","  \n","  ##\n","  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","  ##\n","\n","  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","  drop4 = Dropout(0.5)(conv4)\n","  \n","  ##\n","  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","  ##\n","\n","  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","  drop5 = Dropout(0.5)(conv5)\n","\n","  ##\n","  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","  merge6 = concatenate([drop4,up6], axis = 3)\n","  ##\n","\n","  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","  ##\n","  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","  merge7 = concatenate([conv3,up7], axis = 3)\n","  ##\n","  \n","  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","  ##\n","  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","  merge8 = concatenate([conv2,up8], axis = 3)\n","  ##\n","  \n","  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","  ##\n","  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","  merge9 = concatenate([conv1,up9], axis = 3)\n","  ##\n","  \n","  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","  conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","  model = Model(input = inputs, output = conv10)\n","\n","  model.compile(optimizer = Adam(lr = 1e-6), loss = 'binary_crossentropy', metrics = ['accuracy'])\n","  \n","  model.summary()\n","\n","  if(pretrained_weights):\n","    model.load_weights(pretrained_weights)\n","\n","  return model\n","\n","print('Done')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KTwzeDmPI1Ik","colab_type":"text"},"source":["#Data Augmentation"]},{"cell_type":"code","metadata":{"id":"F9raEp90qXV9","colab_type":"code","colab":{}},"source":["# data_gen_args = dict()\n","\n","data_gen_args = dict(rotation_range=0.2,\n","                  width_shift_range=0.05,\n","                  height_shift_range=0.05,\n","                  shear_range=0.05,\n","                  zoom_range=0.05,\n","                  horizontal_flip=True,\n","                  fill_mode='nearest')\n","\n","\n","print('Done')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJacFad0I7sd","colab_type":"text"},"source":["#Treino"]},{"cell_type":"code","metadata":{"id":"JkWQ74BvtXwG","colab_type":"code","colab":{}},"source":["# training = trainGenerator(8,train_path,'image','label',data_gen_args,save_to_dir = aug_path)\n","training = trainGenerator(4,train_path,'image','label',data_gen_args,save_to_dir = None)\n","\n","model = unet()\n","\n","model_checkpoint = ModelCheckpoint((drive_path+'membrane/unet_membrane.hdf5'), monitor='loss',verbose=1, save_best_only=True)\n","\n","model.fit_generator(training,steps_per_epoch=128,epochs=128,callbacks=[model_checkpoint])\n","\n","print(\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5240MCZyI-vD","colab_type":"text"},"source":["#Teste"]},{"cell_type":"code","metadata":{"id":"UzYF7SNbvMyR","colab_type":"code","colab":{}},"source":["testing = testGenerator(test_path)\n","\n","model = unet()\n","\n","model.load_weights((drive_path+'membrane/unet_membrane.hdf5'))\n","\n","results = model.predict_generator(testing,30,verbose=1)\n","\n","print(\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DHpcvWAcJCmv","colab_type":"text"},"source":["#Salvando os resultados"]},{"cell_type":"code","metadata":{"id":"KCz3G2XVNZO2","colab_type":"code","colab":{}},"source":["saveResult(results_path,results)\n","\n","print(\"Done\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8c83oU0_shij","colab_type":"text"},"source":["\n","---\n","#...\n"]},{"cell_type":"code","metadata":{"id":"Wo0CXepKozVD","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np\n","\n","img= io.imread(results_path+'0_predict.png')\n","#img= cv2.resize(img,(256,256))\n","cv2_imshow(img)\n","\n","#print (img.shape)\n","\n","thr, imgbin = cv2.threshold(img,212,255,cv2.THRESH_BINARY)\n","\n","# thr, imgbin = cv2.threshold(img,200,255,cv2.THRESH_TOZERO)\n","# imgbin = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n","#             cv2.THRESH_BINARY,11,2)\n","\n","cv2_imshow(imgbin)"],"execution_count":null,"outputs":[]}]}